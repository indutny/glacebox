#!/usr/bin/env node
var path = require('path'),
    fs = require('fs'),
    assert = require('assert'),
    request = require('request'),
    async = require('async'),
    nconf = require('nconf'),
    dropbox = require('dropbox'),
    pkgcloud = require('pkgcloud');

var Buffer = require('buffer').Buffer;

nconf.argv().file(path.resolve(
  process.env.HOME,
  '.glacebox.json'
)).defaults({
  dropbox: {},
  aws: {},
  retry: 10000,
  'max-retry': 5,
  parallel: 8
});

var clients = {
  dropbox: new dropbox.Client({
    key: nconf.get('dropbox').key,
    secret: nconf.get('dropbox').secret
  }),
  aws: pkgcloud.storage.createClient({
    provider: 'amazon',
    key: nconf.get('aws').secretAccessKey,
    keyId: nconf.get('aws').accessKeyId
  })
};

// Main
clients.dropbox.authDriver(new dropbox.Drivers.NodeServer(8191));

async.series([
  async.parallel.bind(null, [
    log(clients.dropbox.authenticate.bind(clients.dropbox), 'Dropbox login'),
    log(clients.aws.createContainer.bind(
      clients.aws,
      nconf.get('aws').container
    ), 'AWS container create'),
  ]),
  upload.bind(null, [ '/' ])
], function(err) {
  if (err) throw err;
  console.log('! Done');
});

// Ignore leaks, I'm aware of them
process.setMaxListeners(10000);

function retry(fn, cb, failures) {
  if (!failures) failures = 0;
  fn(function(err) {
    if (err) {
      console.log('Action failed %d times', failures);
      if (failures >= nconf.get('max-retry')) {
        console.log('Stop retrying');
        return cb(err);
      }

      setTimeout(function() {
        retry(fn, cb, failures + 1);
      }, nconf.get('retry'));
      return;
    }

    cb.apply(this, arguments);
  });
}

var transliterate = {
  'а': 'a',
  'б': 'b',
  'в': 'v',
  'г': 'g',
  'д': 'd',
  'е': 'e',
  'ж': 'j',
  'з': 'z',
  'и': 'i',
  'й': 'j',
  'к': 'k',
  'л': 'l',
  'м': 'm',
  'н': 'n',
  'о': 'o',
  'п': 'p',
  'р': 'r',
  'с': 's',
  'т': 't',
  'у': 'u',
  'ф': 'f',
  'х': 'h',
  'ц': 'c',
  'ч': 'ch',
  'ш': 'sh',
  'щ': 'sh',
  'ь': '\'',
  'ы': 'i',
  'э': 'e',
  'ю': 'yu',
  'я': 'ya'
};

function sanitize(path) {
  path = path.replace(/^\//, '');
  path = path.replace(/[^a-z0-9\.\s\-\/]/gi, function(c) {
    var isUpper = c.toLowerCase() !== c;
    var out = transliterate[c.toLowerCase()] || '';
    if (isUpper) out = out.toUpperCase();
    return out;
  });
  path = escape(path);
  return path;
}

var queue = [],
    active = 0;

function upload(file, cb) {
  if (active >= nconf.get('parallel')) {
    queue.push(function() {
      upload(file, cb);
    });
    return;
  }

  var fullPath = path.join.apply(null, file);
  active++;
  var dequeue = function() {
    dequeue = null;
    active--;
    while (queue.length > 0 && active < nconf.get('parallel')) {
      queue.shift()();
    }
  }

  function finish(err) {
    if (dequeue) dequeue();
    cb(err);
  }

  retry(function(cb) {
    clients.dropbox.stat(fullPath, cb);
  }, function(err, stat) {
    if (err) return finish(err);

    if (stat.isFolder) {
      retry(function(cb) {
        clients.dropbox.readdir(fullPath, cb);
      }, function(err, entries) {
        if (err) return finish(err);

        dequeue();
        async.forEach(entries, function(name, cb) {
            upload(file.concat(name), cb);
        }, finish);
      });
    } else {
      retry(function(cb) {
        clients.dropbox.makeUrl(fullPath, { download: true }, cb);
      }, function(err, res) {
        if (err) return finish(err);

        console.log('Uploading %s to S3', fullPath);
        retry(function(cb) {
          clients.aws.upload({
            container: nconf.get('aws').container,
            remote: sanitize(fullPath),
            stream: request(res.url)
          }, cb);
        }, finish);
      });
    }
  });
}

function log(action, msg) {
  return function(cb) {
    var once = false;
    action(function(err) {
      if (once) return;
      once = true;

      if (err) {
        console.error('!!! "%s" failed', msg, err);
      } else {
        console.log(msg);
      }
      cb(err);
    });
  };
};
